{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Wtn5-7bVZ7kX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile as zf\n",
        "import shutil\n",
        "import re\n",
        "import seaborn as sns\n",
        "import random\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import  classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE_bIzkSZT3v"
      },
      "outputs": [],
      "source": [
        "!gdown 1M_u-5UjskP8YbuhagbBdCiNYvTP69swO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb8QsqXxZbxX"
      },
      "outputs": [],
      "source": [
        "files = zf.ZipFile(\"/content/trash_images rev 3.zip\",'r')\n",
        "files.extractall()\n",
        "files.close()\n",
        "os.listdir(os.path.join(os.getcwd(),\"trash_images\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kEy5N2SIZ_D5"
      },
      "outputs": [],
      "source": [
        "def split_indices(folder,seed1,seed2):\n",
        "    n = len(os.listdir(folder))\n",
        "    full_set = list(range(1,n+1))\n",
        "\n",
        "    ## train indices\n",
        "    random.seed(seed1)\n",
        "    train = random.sample(list(range(1,n+1)),int(.7*n))\n",
        "\n",
        "    ## temp\n",
        "    remain = list(set(full_set)-set(train))\n",
        "\n",
        "    ## separate remaining into validation and test\n",
        "    random.seed(seed2)\n",
        "    valid = random.sample(remain,int(.5*len(remain)))\n",
        "    test = list(set(remain)-set(valid))\n",
        "\n",
        "    return(train,valid,test)\n",
        "\n",
        "def get_names(waste_type, indices):\n",
        "    file_names = []\n",
        "    for i in indices:\n",
        "        file_name = f\"{waste_type} ({i}).jpg\"  # Format nama file yang diinginkan\n",
        "        file_names.append(file_name)\n",
        "    return (file_names)\n",
        "\n",
        "def move_files(source_files,destination_folder):\n",
        "    for file in source_files:\n",
        "        shutil.move(file,destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8j3htm2U6_ZW"
      },
      "outputs": [],
      "source": [
        "# Create destination folders for data subset and waste type\n",
        "subsets = ['train', 'test']\n",
        "waste_types = ['glass', 'paper', 'trash']\n",
        "\n",
        "# Ensure destination folders exist\n",
        "for subset in subsets:\n",
        "    for waste_type in waste_types:\n",
        "        folder = os.path.join('data', subset, waste_type)\n",
        "        if not os.path.exists(folder):\n",
        "            os.makedirs(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9GtYbxv7V8q",
        "outputId": "8b3e9d5c-3c9b-4280-fd29-7f96ac2786cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found: trash_images/trash/trash (763).jpg\n"
          ]
        }
      ],
      "source": [
        "# Move files to destination folders for each waste type\n",
        "for waste_type in waste_types:\n",
        "    source_folder = os.path.join('trash_images', waste_type)\n",
        "    train_ind, test_ind = split_indices(source_folder, 1)\n",
        "\n",
        "    # Move source files to train\n",
        "    train_names = get_names(waste_type, train_ind)\n",
        "    train_source_files = [os.path.join(source_folder, name) for name in train_names]\n",
        "    train_dest = os.path.join(\"data/train\", waste_type)\n",
        "    move_files(train_source_files, train_dest)\n",
        "\n",
        "    # Move source files to test\n",
        "    test_names = get_names(waste_type, test_ind)\n",
        "    test_source_files = [os.path.join(source_folder, name) for name in test_names]\n",
        "    test_dest = os.path.join(\"data/test\", waste_type)\n",
        "    move_files(test_source_files, test_dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tXUG4RhIee1",
        "outputId": "7761c0c8-415f-4578-fd84-e5e10520de0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False,\n",
        "                     input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Wd84GxKNMLg"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IceGndmqNOEI"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RipWKqM5Qg-D"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7JUe3uhNUQu"
      },
      "outputs": [],
      "source": [
        "len(model.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ccaWx3_4NUh-"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y73CjSTbNbDu"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uS9kDSOqNcsb"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   fill_mode='nearest',\n",
        "                                   horizontal_flip=True,\n",
        "                                   )\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BfFLVzsNgFo"
      },
      "outputs": [],
      "source": [
        "from imutils import paths\n",
        "train_dir = 'data/train'\n",
        "validation_dir = 'data/valid/'\n",
        "test_dir = 'data/test/'\n",
        "totalTrain = len(list(paths.list_images(train_dir)))\n",
        "totalVal = len(list(paths.list_images(validation_dir)))\n",
        "totalTest = len(list(paths.list_images(test_dir)))\n",
        "print(\"Total Training: \", totalTrain)\n",
        "print(\"Total Validation: \",totalVal)\n",
        "print(\"Total test: \", totalTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "y-2Cf6LsNh_4"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "TARGET_SIZE = (224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYcRII-mNody",
        "outputId": "f94477da-e441-4b0b-a4af-3008e2be0115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3361 images belonging to 6 classes.\n",
            "Found 559 images belonging to 6 classes.\n",
            "Found 857 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   class_mode='categorical',\n",
        "                                                    color_mode='rgb',\n",
        "                                                    shuffle=True,\n",
        "                                                   target_size=TARGET_SIZE)\n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   color_mode='rgb',\n",
        "                                                   class_mode='categorical',\n",
        "                                                   shuffle=False,\n",
        "                                                   target_size=TARGET_SIZE)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    class_mode=\"categorical\",\n",
        "    color_mode='rgb',\n",
        "    target_size=TARGET_SIZE,\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vAeLVH7NqMa"
      },
      "outputs": [],
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=totalTrain // BATCH_SIZE,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=totalVal // BATCH_SIZE,\n",
        "    epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi"
      ],
      "metadata": {
        "id": "zWe2JLbGYwGN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DhGcrUuOcWf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot the training loss and accuracy\n",
        "N = np.arange(0, 50)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training Loss and Accuracy on CIFAR-10\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.title(\"Training Loss and Accuracy on CIFAR-10\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84vdPhRAOmZF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}